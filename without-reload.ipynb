{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7029b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import configparser\n",
    "import interpolation as inter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "ROI_RECTANGLE = 0\n",
    "ROI_POLYGON = 1\n",
    "\n",
    "EDSR = -1\n",
    "INTER_NEAREST = cv2.INTER_NEAREST\n",
    "INTER_LINEAR = cv2.INTER_LINEAR\n",
    "INTER_CUBIC = cv2.INTER_CUBIC\n",
    "INTER_AREA = cv2.INTER_AREA\n",
    "INTER_LANCZOS4 = cv2.INTER_LANCZOS4\n",
    "INTER_LINEAR_EXACT = cv2.INTER_LINEAR_EXACT\n",
    "INTER_NEAREST_EXACT = cv2.INTER_NEAREST_EXACT\n",
    "INTER_MAX = cv2.INTER_MAX\n",
    "WARP_FILL_OUTLIERS = cv2.WARP_FILL_OUTLIERS\n",
    "WARP_INVERSE_MAP = cv2.WARP_INVERSE_MAP\n",
    "WARP_RELATIVE_MAP = cv2.WARP_RELATIVE_MAP\n",
    "\n",
    "drawing = False\n",
    "points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35240512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 용량이 큰 이미지 분할해서 upscaling 할 수 있도록 구현\n",
    "# 분할된 부분이 겹치도록 - 겹친 후에 블렌딩으로 자연스럽게\n",
    "\n",
    "PIXELS_LIMIT = 281000\n",
    "OVERLAP_HALF_LENGTH = 20\n",
    "\n",
    "_upscaled_fraction_num = 0\n",
    "\n",
    "def _upscale_img(img, scaler):\n",
    "    \"\"\"\n",
    "    img: 이미지 ndarray\n",
    "    scaler: 배율(2 or 3 or 4)\n",
    "    \"\"\"\n",
    "    # if scaler not in [2, 3, 4]:\n",
    "    #     print(f\"Invalid scaler value: {scaler}. Must be 2, 3 or 4.\")\n",
    "    #     return None\n",
    "    # if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "    #     print(\"No CUDA-enabled GPU found.\")\n",
    "    #     return None\n",
    "\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    try:\n",
    "        sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading model: {e}\")\n",
    "        return None\n",
    "\n",
    "    # gpu acceleration\n",
    "    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    sr.setModel('edsr', scaler)\n",
    "\n",
    "    try:\n",
    "        result = sr.upsample(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upscaling: {e}\")\n",
    "        return None\n",
    "    global _upscaled_fraction_num\n",
    "    _upscaled_fraction_num += 1\n",
    "    return result\n",
    "\n",
    "def _upscale_large_img_helper(img, scaler):\n",
    "    if scaler not in [2, 3, 4]:\n",
    "        print(f\"Invalid scaler value: {scaler}. Must be 2, 3 or 4.\")\n",
    "        return None\n",
    "    if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "        print(\"No CUDA-enabled GPU found.\")\n",
    "        return None\n",
    "    \n",
    "    h, w, c = img.shape\n",
    "    if h * w < PIXELS_LIMIT:\n",
    "        return _upscale_img(img, scaler)\n",
    "    \n",
    "    if w < h:\n",
    "        upper = np.zeros((scaler*h, scaler*w, c))\n",
    "        below = np.zeros((scaler*h, scaler*w, c))\n",
    "\n",
    "        upper[0:scaler*(h//2 + OVERLAP_HALF_LENGTH),:] = _upscale_large_img_helper(img[0:(h//2 + OVERLAP_HALF_LENGTH),:], scaler=scaler)\n",
    "        below[scaler*(h//2 - OVERLAP_HALF_LENGTH):scaler*h,:] = _upscale_large_img_helper(img[(h//2 - OVERLAP_HALF_LENGTH):h,:], scaler=scaler)\n",
    "\n",
    "        # h//2 - OVERLAP_HALF_LENGTH ~ h//2 + OVERLAP_HALF_LENGTH\n",
    "        alpha = np.ones((scaler*h, scaler*w)) * np.arange(scaler * h).reshape(-1, 1)\n",
    "        start = scaler * (h//2 - OVERLAP_HALF_LENGTH)\n",
    "        end = scaler * (h//2 + OVERLAP_HALF_LENGTH)\n",
    "        alpha = np.clip((alpha - start) / (end - start), 0, 1)\n",
    "\n",
    "        alpha_3ch = np.repeat(alpha[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "        upper_f = upper.astype(np.float32)\n",
    "        below_f = below.astype(np.float32)\n",
    "\n",
    "        blended = upper_f * (1-alpha_3ch) + below_f * alpha_3ch\n",
    "        blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "        return blended\n",
    "    \n",
    "    else:\n",
    "        left = np.zeros((scaler*h, scaler*w, c))\n",
    "        right = np.zeros((scaler*h, scaler*w, c))\n",
    "        \n",
    "        left[:,0:scaler*(w//2 + OVERLAP_HALF_LENGTH)] = _upscale_large_img_helper(img[:,0:(w//2 + OVERLAP_HALF_LENGTH)], scaler=scaler)\n",
    "        right[:,scaler*(w//2 - OVERLAP_HALF_LENGTH):scaler*w] = _upscale_large_img_helper(img[:,(w//2 - OVERLAP_HALF_LENGTH):w], scaler=scaler)\n",
    "\n",
    "        # w//2 - OVERLAP_HALF_LENGTH ~ w//2 + OVERLAP_HALF_LENGTH\n",
    "        alpha = np.ones((scaler*h, scaler*w)) * np.arange(scaler * w).reshape(1, -1)\n",
    "        start = scaler * (w//2 - OVERLAP_HALF_LENGTH)\n",
    "        end = scaler * (w//2 + OVERLAP_HALF_LENGTH)\n",
    "        alpha = np.clip((alpha - start) / (end - start), 0, 1)\n",
    "        \n",
    "        alpha_3ch = np.repeat(alpha[:, :, np.newaxis], 3, axis=2)\n",
    "        \n",
    "        left_f = left.astype(np.float32)\n",
    "        right_f = right.astype(np.float32)\n",
    "\n",
    "        blended = left_f * (1-alpha_3ch) + right_f * alpha_3ch\n",
    "        blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "        return blended\n",
    "\n",
    "def upscale_large_img(img, scaler):\n",
    "    \"\"\"\n",
    "    img: 이미지 ndarray\n",
    "    scaler: 배율(2 or 3 or 4)\n",
    "    \"\"\"\n",
    "    global _upscaled_fraction_num\n",
    "    _upscaled_fraction_num = 0\n",
    "\n",
    "    t1 = time.time()\n",
    "    result = _upscale_large_img_helper(img, scaler=scaler)\n",
    "    t2 = time.time()\n",
    "    if _upscaled_fraction_num > 1:\n",
    "        print(f'upscaled after being divided into {_upscaled_fraction_num} fragments.')\n",
    "    else:\n",
    "        print(f'upscaled without fraction')\n",
    "    print(f'{t2-t1} sec taken')\n",
    "    _upscaled_fraction_num = 0\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Lenna_(test_image).png')\n",
    "scaler = 4\n",
    "\n",
    "if scaler not in [2, 3, 4]:\n",
    "    print(f\"Invalid scaler value: {scaler}. Must be 2, 3 or 4.\")\n",
    "\n",
    "if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "    print(\"No CUDA-enabled GPU found.\")\n",
    "\n",
    "sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "try:\n",
    "    sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "except Exception as e:\n",
    "    print(f\"Error reading model: {e}\")\n",
    "\n",
    "# gpu acceleration\n",
    "sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "sr.setModel('edsr', scaler)\n",
    "\n",
    "try:\n",
    "    result = sr.upsample(img1)\n",
    "except Exception as e:\n",
    "    print(f\"Error during upscaling: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f6e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "197.584814786911, 369.85457468032837 -> 0.5342229846898255\n"
     ]
    }
   ],
   "source": [
    "def upscale_single_img(img, scaler):\n",
    "\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "\n",
    "    # gpu acceleration\n",
    "    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    sr.setModel('edsr', scaler)\n",
    "\n",
    "    result = sr.upsample(img)\n",
    "\n",
    "    return result\n",
    "\n",
    "def upscale_mult_img(scaler, *args):\n",
    "\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "\n",
    "    # gpu acceleration\n",
    "    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    sr.setModel('edsr', scaler)\n",
    "\n",
    "    result = []\n",
    "    for img in args:\n",
    "        res = sr.upsample(img)\n",
    "        result.append(res)\n",
    "    return result\n",
    "\n",
    "_img = cv2.imread('Lenna_(test_image).png')\n",
    "img2 = cv2.rotate(_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "t1 = time.time()\n",
    "upscaleds_mult = upscale_mult_img(4, _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2, \n",
    "                                  _img, img2, _img, img2, _img, img2, _img, img2, _img, img2) # 100\n",
    "t2 = time.time()\n",
    "\n",
    "\n",
    "upscaleds_sing = []\n",
    "for _ in range(50):\n",
    "    up1 = upscale_single_img(_img, 4)\n",
    "    up2 = upscale_single_img(img2, 4)\n",
    "    upscaleds_sing.append(up1)\n",
    "    upscaleds_sing.append(up2)\n",
    "t3 = time.time()\n",
    "\n",
    "print(len(upscaleds_mult))\n",
    "print(len(upscaleds_sing))\n",
    "\n",
    "print(f'{t2-t1}, {t3-t2} -> {(t2-t1) / (t3-t2)}')\n",
    "\n",
    "\n",
    "# for upscaled in upscaleds:\n",
    "#     cv2.imshow('test', upscaled)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "100\n",
    "100\n",
    "197.584814786911, 369.85457468032837 -> 0.5342229846898255\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ffccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "안1 함수 안에 함수로 모델 공유하도록\n",
    "안2 모델을 파라미터로 넘기도록\n",
    "\"\"\"\n",
    "\n",
    "# TODO: np 대신 cp 적용 -> 메모리 해제 시간 고려 효율\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8872a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS_LIMIT = 281000\n",
    "OVERLAP_HALF_LENGTH = 20\n",
    "\n",
    "def upsample_large_img(img, scaler):\n",
    "    upsampled_fraction_num = 0\n",
    "    \n",
    "    def upsample_img(_img):\n",
    "        nonlocal upsampled_fraction_num\n",
    "        h, w, c = _img.shape\n",
    "        if h * w < PIXELS_LIMIT:\n",
    "            upsampled_fraction_num += 1\n",
    "            return sr.upsample(_img)\n",
    "        \n",
    "        if w < h:\n",
    "            upper = np.zeros((scaler*h, scaler*w, c))\n",
    "            below = np.zeros((scaler*h, scaler*w, c))\n",
    "\n",
    "            upper[0:scaler*(h//2 + OVERLAP_HALF_LENGTH),:] = upsample_img(_img[0:(h//2 + OVERLAP_HALF_LENGTH),:])\n",
    "            below[scaler*(h//2 - OVERLAP_HALF_LENGTH):scaler*h,:] = upsample_img(_img[(h//2 - OVERLAP_HALF_LENGTH):h,:])\n",
    "\n",
    "            # h//2 - OVERLAP_HALF_LENGTH ~ h//2 + OVERLAP_HALF_LENGTH\n",
    "            alpha = np.ones((scaler*h, scaler*w)) * np.arange(scaler * h).reshape(-1, 1)\n",
    "            start = scaler * (h//2 - OVERLAP_HALF_LENGTH)\n",
    "            end = scaler * (h//2 + OVERLAP_HALF_LENGTH)\n",
    "            alpha = np.clip((alpha - start) / (end - start), 0, 1)\n",
    "\n",
    "            alpha_3ch = np.repeat(alpha[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "            upper_f = upper.astype(np.float32)\n",
    "            below_f = below.astype(np.float32)\n",
    "\n",
    "            blended = upper_f * (1-alpha_3ch) + below_f * alpha_3ch\n",
    "            blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "            return blended\n",
    "        else:\n",
    "            left = np.zeros((scaler*h, scaler*w, c))\n",
    "            right = np.zeros((scaler*h, scaler*w, c))\n",
    "            \n",
    "            left[:,0:scaler*(w//2 + OVERLAP_HALF_LENGTH)] = upsample_img(_img[:,0:(w//2 + OVERLAP_HALF_LENGTH)])\n",
    "            right[:,scaler*(w//2 - OVERLAP_HALF_LENGTH):scaler*w] = upsample_img(_img[:,(w//2 - OVERLAP_HALF_LENGTH):w])\n",
    "\n",
    "            # w//2 - OVERLAP_HALF_LENGTH ~ w//2 + OVERLAP_HALF_LENGTH\n",
    "            alpha = np.ones((scaler*h, scaler*w)) * np.arange(scaler * w).reshape(1, -1)\n",
    "            start = scaler * (w//2 - OVERLAP_HALF_LENGTH)\n",
    "            end = scaler * (w//2 + OVERLAP_HALF_LENGTH)\n",
    "            alpha = np.clip((alpha - start) / (end - start), 0, 1)\n",
    "            \n",
    "            alpha_3ch = np.repeat(alpha[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "            left_f = left.astype(np.float32)\n",
    "            right_f = right.astype(np.float32)\n",
    "\n",
    "            blended = left_f * (1-alpha_3ch) + right_f * alpha_3ch\n",
    "            blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "            return blended\n",
    "        \n",
    "    if scaler not in [2, 3, 4]:\n",
    "        print(f\"Invalid scaler value: {scaler}. Must be 2, 3 or 4.\")\n",
    "        return None\n",
    "    if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "        print(\"No CUDA-enabled GPU found.\")\n",
    "        return None\n",
    "\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    try:\n",
    "        sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading model: {e}\")\n",
    "        return None\n",
    "\n",
    "    # gpu acceleration\n",
    "    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    sr.setModel('edsr', scaler)\n",
    "\n",
    "    t1 = time.time()\n",
    "    result = upsample_img(img)\n",
    "    t2 = time.time()\n",
    "\n",
    "    if upsampled_fraction_num > 1:\n",
    "        print(f'upscaled after being divided into {upsampled_fraction_num} fragments.')\n",
    "    else:\n",
    "        print(f'upscaled without fraction')\n",
    "    print(f'{t2-t1} sec taken')\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "288b4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upscaled after being divided into 16 fragments.\n",
      "25.06098985671997 sec taken\n"
     ]
    }
   ],
   "source": [
    "_img = cv2.imread('sample-images-png/1920x1080.png')\n",
    "\n",
    "# upsampled1 = upscale_large_img(img, 4)\n",
    "upsampled2 = upsample_large_img(_img, 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d7f1020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nupsampled2\\nupscaled after being divided into 16 fragments.\\n25.543002367019653 sec taken\\n\\nupscaled after being divided into 16 fragments.\\n25.06098985671997 sec taken\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "upsampled1\n",
    "upscaled after being divided into 16 fragments.\n",
    "40.26908230781555 sec taken\n",
    "\n",
    "upscaled after being divided into 16 fragments.\n",
    "39.244662284851074 sec taken\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "upsampled2\n",
    "upscaled after being divided into 16 fragments.\n",
    "25.543002367019653 sec taken\n",
    "\n",
    "upscaled after being divided into 16 fragments.\n",
    "25.06098985671997 sec taken\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a029966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('test', upsampled1)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('test', upsampled2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "182b041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    foovar = 234\n",
    "    def bar():\n",
    "        nonlocal foovar\n",
    "        foovar += 1\n",
    "        print(foovar)\n",
    "    bar()\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c5d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upscaled after being divided into 16 fragments.\n",
      "25.34834623336792 sec taken qqqqq\n"
     ]
    }
   ],
   "source": [
    "import mrs3 as mr\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('sample-images-png/1920x1080.png')\n",
    "\n",
    "upscaled = mr.upscale_large_img(img, 4)\n",
    "\n",
    "cv2.imshow('upscaled', upscaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1436aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upscale_img_test(img, scaler):\n",
    "    \"\"\"\n",
    "    img: 이미지 ndarray\n",
    "    scaler: 배율(2 or 3 or 4)\n",
    "    \"\"\"\n",
    "    # if scaler not in [2, 3, 4]:\n",
    "    #     print(f\"Invalid scaler value: {scaler}. Must be 2, 3 or 4.\")\n",
    "    #     return None\n",
    "    # if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "    #     print(\"No CUDA-enabled GPU found.\")\n",
    "    #     return None\n",
    "\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    try:\n",
    "        sr.readModel(f'models/EDSR_x{scaler}.pb')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading model: {e}\")\n",
    "        return None\n",
    "\n",
    "    # gpu acceleration\n",
    "    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    sr.setModel('edsr', scaler)\n",
    "\n",
    "    try:\n",
    "        result = sr.upsample(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upscaling: {e}\")\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "img = cv2.imread('Lenna_(test_image).png')\n",
    "upscaled = _upscale_img_test(img, 4)\n",
    "cv2.imshow('test', upscaled)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460396b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrs3exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
